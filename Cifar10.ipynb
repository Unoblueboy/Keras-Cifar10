{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for classification of CIFAR 10\n",
    "\n",
    "## Import Modules\n",
    "\n",
    "some notes taken from [here](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from numpy.random import randint, random, choice\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, SpatialDropout2D\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import to_categorical, Progbar\n",
    "\n",
    "from keras.optimizers import Adagrad, SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "[here](https://keras.io/api/preprocessing/image/#imagedatagenerator-class) you can look into ImageDataGenerator class as a way to generate more data for the model to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture\n",
    "\n",
    "We are going to attempt a form of [Hyperparameter Optimisation](https://en.wikipedia.org/wiki/Hyperparameter_optimization), specifically by Evolutionary Optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 267s 3s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 100us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.4259693344575626\n",
      "This has parameters: [104, 84, 0.3168678189374343, 16, 43, 0.7508066875923568, 113, 113, 0.24709323436613395, 46, 0.8545227961773413]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7090241866493531\n",
      "This has parameters: [33, 82, 0.4293056185402968, 37, 70, 0.15049520102269875, 45, 50, 0.09063027861111506, 52, 0.9548030978074237]\n",
      "\n",
      "Iteration 2\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 195s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 105us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.3995845177344088\n",
      "This has parameters: [122.0, 87.0, 0.06469539915627398, 101.0, 91.0, 0.6967589129606258, 82.0, 53.0, 0.7070066662225779, 76.0, 0.3045356385763406]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7105837530504537\n",
      "This has parameters: [77.0, 95.0, 0.7854155762291246, 11.0, 6.0, 0.8602385646617118, 120.0, 117.0, 0.13571077145898847, 82.0, 0.06271356179449039]\n",
      "\n",
      "Iteration 3\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 197s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 105us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.2334744137924363\n",
      "This has parameters: [24.0, 72.0, 0.6940665994449243, 122.0, 59.0, 0.8642766796763256, 113.0, 93.0, 0.7372073161587377, 73.0, 0.8660549038001054]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7922281959668108\n",
      "This has parameters: [103.0, 119.0, 0.9864537967730822, 38.0, 38.0, 0.3740978353283688, 34.0, 15.0, 0.20880319923590573, 109.0, 0.7373092998042831]\n",
      "\n",
      "Iteration 4\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 192s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 110us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.23754651998166\n",
      "This has parameters: [117.0, 5.0, 0.9376224154607938, 2.0, 38.0, 0.3740978353283688, 124.0, 110.0, 0.020762725688960426, 108.0, 0.06271356179449039]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6451023456709706\n",
      "This has parameters: [101.0, 29.0, 0.46654471903788786, 35.0, 78.0, 0.4595632445060054, 46.0, 110.0, 0.020762725688960426, 92.0, 0.9412504084400685]\n",
      "\n",
      "Iteration 5\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 195s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 100us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.5450409246921981\n",
      "This has parameters: [17.0, 19.0, 0.4155673483562846, 101.0, 40.0, 0.563158738820283, 68.0, 100.0, 0.39602523960352465, 126.0, 0.6136011324728924]\n",
      "\n",
      "Minimum Fitness this iteration: 0.8018601136080405\n",
      "This has parameters: [36.0, 128.0, 0.7355660212452785, 67.0, 1.0, 0.6800689310778191, 118.0, 11.0, 0.3365922947722425, 17.0, 0.2832728826715747]\n",
      "\n",
      "Iteration 6\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 194s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 105us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.3949792308340891\n",
      "This has parameters: [34.0, 114.0, 0.17061610858471965, 107.0, 23.0, 0.34662343452705724, 126.0, 79.0, 0.7736558035074131, 82.0, 0.06271356179449039]\n",
      "\n",
      "Minimum Fitness this iteration: 0.5767163273730276\n",
      "This has parameters: [117.0, 5.0, 0.9376224154607938, 89.0, 93.0, 0.33684298313716254, 122.0, 20.0, 0.8887135861986394, 7.0, 0.5480710657633989]\n",
      "\n",
      "Iteration 7\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 201s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.5214592291093858\n",
      "This has parameters: [116.0, 78.0, 0.3774196034259629, 97.0, 104.0, 0.43186701881398715, 20.0, 57.0, 0.16212026070883323, 24.0, 0.37541680856228954]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7160694460635657\n",
      "This has parameters: [116.0, 90.0, 0.7310247171263172, 39.0, 100.0, 0.6570984427319303, 126.0, 79.0, 0.9768555901314953, 96.0, 0.31839912153877425]\n",
      "\n",
      "Iteration 8\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 195s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 120us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.2636500323169582\n",
      "This has parameters: [10.0, 81.0, 0.6831943889661639, 80.0, 9.0, 0.8312618075525444, 34.0, 121.0, 0.20880319923590573, 92.0, 0.9412504084400685]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6860368106336224\n",
      "This has parameters: [34.0, 114.0, 0.17061610858471965, 113.0, 23.0, 0.9382384150011039, 33.0, 22.0, 0.8081669695729322, 9.0, 0.6976134802689392]\n",
      "\n",
      "Iteration 9\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 195s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 120us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.3453112009593502\n",
      "This has parameters: [36.0, 66.0, 0.629297820832833, 76.0, 64.0, 0.5520663489433151, 114.0, 93.0, 0.43108298327344674, 73.0, 0.8660549038001054]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7441395467940388\n",
      "This has parameters: [34.0, 113.0, 0.6201051286709753, 102.0, 104.0, 0.009254851565067224, 8.0, 110.0, 0.21284901465567496, 68.0, 0.12497660690754753]\n",
      "\n",
      "Iteration 10\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 199s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.4011229894642314\n",
      "This has parameters: [36.0, 5.0, 0.9182047484138108, 119.0, 25.0, 0.4162193972873224, 8.0, 58.0, 0.6513082095895363, 110.0, 0.9531120971602064]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7311735260977669\n",
      "This has parameters: [5.0, 114.0, 0.17061610858471965, 2.0, 34.0, 0.01496658119688421, 24.0, 23.0, 0.27505050330101033, 119.0, 0.05205289830235005]\n",
      "\n",
      "Iteration 11\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 201s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 140us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.6162256899359857\n",
      "This has parameters: [116.0, 78.0, 0.5578516468643788, 58.0, 71.0, 0.8248282550282061, 73.0, 33.0, 0.01997337859993331, 60.0, 0.2159803578591608]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7657015650395048\n",
      "This has parameters: [126.0, 56.0, 0.5005993551823924, 64.0, 50.0, 0.3740978353283688, 70.0, 79.0, 0.7736558035074131, 59.0, 0.7066468956535492]\n",
      "\n",
      "Iteration 12\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 203s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.5933067477022993\n",
      "This has parameters: [14.0, 57.0, 0.5912410861559905, 197.0, 85.0, 0.5474867723373825, 117.0, 55.0, 0.27692424728968135, 17.0, 0.35278107138456294]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6815295310600713\n",
      "This has parameters: [17.0, 19.0, 0.4155673483562846, 197.0, 104.0, 0.36711786095081467, 8.0, 58.0, 0.34338303344483423, 116.0, 0.7981827427896839]\n",
      "\n",
      "Iteration 13\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 200s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 105us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.2498434718129219\n",
      "This has parameters: [20.0, 114.0, 0.17061610858471965, 49.0, 63.0, 0.7238162300259128, 124.0, 110.0, 0.9846373605971998, 30.0, 0.13990647664238143]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6974357689826064\n",
      "This has parameters: [121.0, 1.0, 0.6898332578336456, 17.0, 57.0, 0.3111484860558611, 120.0, 94.0, 0.10111539464570662, 60.0, 0.4452725605435688]\n",
      "\n",
      "Iteration 14\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 208s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 115us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.3782226728088627\n",
      "This has parameters: [25.0, 85.0, 0.16708960307306508, 17.0, 57.0, 0.3111484860558611, 8.0, 97.0, 0.8078468738929941, 116.0, 0.2886698126803189]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7184333688616567\n",
      "This has parameters: [117.0, 113.0, 0.4155673483562846, 118.0, 25.0, 0.8053615017033756, 117.0, 57.0, 0.10111539464570662, 60.0, 0.4452725605435688]\n",
      "\n",
      "Iteration 15\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 209s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 125us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.2525926218729302\n",
      "This has parameters: [126.0, 13.0, 0.5005993551823924, 72.0, 17.0, 0.3740978353283688, 122.0, 17.0, 0.1973171918790364, 116.0, 0.6997503232179828]\n",
      "\n",
      "Minimum Fitness this iteration: 0.692092882226592\n",
      "This has parameters: [114.0, 57.0, 0.006044680691923654, 15.0, 1.0, 0.5806645385845266, 7.0, 50.0, 0.12664229596971166, 60.0, 0.2159803578591608]\n",
      "\n",
      "Iteration 16\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 205s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 130us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.4353998317239056\n",
      "This has parameters: [20.0, 114.0, 0.17061610858471965, 128.0, 36.0, 0.9686965281318236, 77.0, 49.0, 0.4730453279081972, 60.0, 0.4452725605435688]\n",
      "\n",
      "Minimum Fitness this iteration: 0.5767163273730276\n",
      "This has parameters: [10.0, 1.0, 0.6898332578336456, 123.0, 82.0, 0.7238162300259128, 85.0, 80.0, 0.01997337859993331, 54.0, 0.6866252544704655]\n",
      "\n",
      "Iteration 17\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 201s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 135us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.4103891680577418\n",
      "This has parameters: [36.0, 112.0, 0.07148403258762925, 30.0, 113.0, 0.3751223751435496, 115.0, 58.0, 0.5139042961666588, 68.0, 0.9412504084400685]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7707655143861611\n",
      "This has parameters: [20.0, 114.0, 0.17061610858471965, 2.0, 44.0, 0.043445596916826146, 8.0, 97.0, 0.8078468738929941, 116.0, 0.2886698126803189]\n",
      "\n",
      "Iteration 18\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 205s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 120us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.3751976813835636\n",
      "This has parameters: [126.0, 43.0, 0.3930827076153567, 72.0, 107.0, 0.3740978353283688, 8.0, 97.0, 0.894114439616396, 10.0, 0.2886698126803189]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6852835232729027\n",
      "This has parameters: [102.0, 66.0, 0.6640850132124844, 31.0, 113.0, 0.3751223751435496, 8.0, 97.0, 0.4083526659090878, 61.0, 0.2886698126803189]\n",
      "\n",
      "Iteration 19\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 210s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 130us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.259492136470701\n",
      "This has parameters: [110.0, 117.0, 0.14003012988251884, 72.0, 9.0, 0.3740978353283688, 120.0, 94.0, 0.1880079875172167, 21.0, 0.2886698126803189]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6875458141061819\n",
      "This has parameters: [117.0, 113.0, 0.4155673483562846, 27.0, 26.0, 0.8248282550282061, 8.0, 97.0, 0.032269367978276065, 54.0, 0.6866252544704655]\n",
      "\n",
      "Iteration 20\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 214s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 160us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.2959868941322215\n",
      "This has parameters: [117.0, 43.0, 0.051131952582649465, 2.0, 50.0, 0.1430710563827502, 122.0, 67.0, 0.1973171918790364, 51.0, 0.6714726549261382]\n",
      "\n",
      "Minimum Fitness this iteration: 0.6898156297859318\n",
      "This has parameters: [8.0, 113.0, 0.4155673483562846, 51.0, 37.0, 0.3111484860558611, 77.0, 49.0, 0.7583342056985043, 32.0, 0.123674111075321]\n",
      "\n",
      "Iteration 21\n",
      "Calculating Fitness\n",
      "100/100 [==============================] - 217s 2s/step\n",
      "Evolving\n",
      "100/100 [==============================] - 0s 120us/step\n",
      "\n",
      "Maximum Fitness this iteration: 1.666715267168621\n",
      "This has parameters: [105.0, 106.0, 0.07148403258762925, 91.0, 82.0, 0.6056116795739639, 73.0, 121.0, 0.4676138859567145, 60.0, 0.261751893640368]\n",
      "\n",
      "Minimum Fitness this iteration: 0.7775695386952991\n",
      "This has parameters: [117.0, 43.0, 0.051131952582649465, 2.0, 50.0, 0.1430710563827502, 122.0, 67.0, 0.1973171918790364, 51.0, 0.6714726549261382]\n",
      "\n",
      "Iteration 22\n",
      "Calculating Fitness\n",
      " 21/100 [=====>........................] - ETA: 2:53"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[936] and type int8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_2998/conv2d_17989/BiasAdd/BiasAddGrad (defined at <ipython-input-17-201589d8e011>:62) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8023730]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-201589d8e011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             model.fit(X_train[0:num_data_samples], Y_train[0:num_data_samples], batch_size=64,\n\u001b[1;32m---> 62\u001b[1;33m                       epochs=iter_epochs, verbose=0)\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[936] and type int8 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node gradient_tape/sequential_2998/conv2d_17989/BiasAdd/BiasAddGrad (defined at <ipython-input-17-201589d8e011>:62) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_8023730]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "default_params = [32, 32, 0.25, 64, 64, 0.25, 128, 128, 0.25, 128, 0.9]\n",
    "hyperparams = default_params[:]\n",
    "\n",
    "# Need to generate first iteration of hyper params\n",
    "models_per_iter = 100\n",
    "total_iter = 100\n",
    "iter_epochs = 10\n",
    "mut_prob = 0.1\n",
    "min_mut_prob = 1e-3\n",
    "mut_decay_rate = 0.99\n",
    "num_data_samples = 200\n",
    "cur_model_params = [[230, 256, 0.5867159955773108, 197, 104, 0.6994386884226651, 124, 104, 0.16212026070883323, 107, 0.7392635793983017]]\n",
    "t = len(cur_model_params)\n",
    "for i in range(models_per_iter-t):\n",
    "    params = [randint(1,128 + 1),\n",
    "              randint(1,128 + 1),\n",
    "              random(),\n",
    "              randint(1,128 + 1),\n",
    "              randint(1,128 + 1),\n",
    "              random(),\n",
    "              randint(1,128 + 1),\n",
    "              randint(1,128 + 1),\n",
    "              random(),\n",
    "              randint(1,128 + 1),\n",
    "              random()]\n",
    "    cur_model_params.append(params)\n",
    "\n",
    "\n",
    "try:\n",
    "    # now to run evolutionary algorithm, we'll make the fitness function test accuracy\n",
    "    for cur_iter in range(total_iter):\n",
    "        print(\"Iteration {}\".format(cur_iter + 1))\n",
    "        fitness = np.zeros(models_per_iter)\n",
    "        print(\"Calculating Fitness\")\n",
    "        fit_prog = Progbar(models_per_iter)\n",
    "        for i in range(models_per_iter):\n",
    "            params = cur_model_params[i]\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(params[0], (3,3), activation = 'relu', padding='same', input_shape=(32, 32, 3)))\n",
    "            model.add(Conv2D(params[1], (3,3), activation = 'relu', padding='same'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(SpatialDropout2D(params[2]))\n",
    "            model.add(Conv2D(params[3], (3,3), activation = 'relu', padding='same'))\n",
    "            model.add(Conv2D(params[4], (3,3), activation = 'relu', padding='same'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(SpatialDropout2D(params[5]))\n",
    "            model.add(Conv2D(params[6], (3,3), activation = 'relu', padding='same'))\n",
    "            model.add(Conv2D(params[7], (3,3), activation = 'relu', padding='same'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            model.add(SpatialDropout2D(params[8]))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(params[9], activation='relu'))\n",
    "            model.add(Dropout(params[10]))\n",
    "            model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=Adam(epsilon=0.1),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            model.fit(X_train[0:num_data_samples], Y_train[0:num_data_samples], batch_size=64,\n",
    "                      epochs=iter_epochs, verbose=0)\n",
    "\n",
    "            _, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "            \n",
    "            del model\n",
    "\n",
    "            fitness[i] = 3**(10*acc-1)\n",
    "\n",
    "            fit_prog.add(1)\n",
    "\n",
    "        if (cur_iter < total_iter - 1):\n",
    "            print(\"Evolving\")\n",
    "            evolve_prog = Progbar(models_per_iter)\n",
    "            # now to do the evolutionary part\n",
    "            temp_model_params = []\n",
    "            ind_argmax = np.argmax(fitness)\n",
    "            if type(ind_argmax) in [np.int64, int]:\n",
    "                ind_argmax = [ind_argmax]\n",
    "            for ind in ind_argmax:\n",
    "                temp_model_params.append(cur_model_params[np.argmax(fitness)])\n",
    "                evolve_prog.add(1)\n",
    "            for i in range(models_per_iter-len(ind_argmax)):\n",
    "                # first select 2 parents\n",
    "                indices = choice(np.arange(models_per_iter), size = 2, p=fitness/np.sum(fitness), replace=True)\n",
    "                p1 = cur_model_params[indices[0]]\n",
    "                p2 = cur_model_params[indices[1]]\n",
    "                temp_num = randint(0, 3)\n",
    "                temp_params = []\n",
    "\n",
    "                # cross-over\n",
    "                if temp_num == 0:\n",
    "                    temp_params = p1[0:3] + p2[3:]\n",
    "                elif temp_num == 1:\n",
    "                    temp_params = p1[0:6] + p2[6:]\n",
    "                else:\n",
    "                    temp_params = p1[0:9] + p2[9:]\n",
    "\n",
    "                # mutation\n",
    "                mut_vec = (random(len(p1)) < mut_prob).astype('int32')\n",
    "\n",
    "                temp_params_2 = np.array([randint(1,128 + 1),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      random(),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      random(),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      random(),\n",
    "                                      randint(1,128 + 1),\n",
    "                                      random()])\n",
    "                temp_params = list(np.multiply(np.array(temp_params), 1-mut_vec) + np.multiply(temp_params_2, mut_vec))\n",
    "\n",
    "                temp_model_params.append(temp_params)\n",
    "\n",
    "                evolve_prog.add(1)\n",
    "\n",
    "            print()\n",
    "            print(\"Maximum Fitness this iteration: {}\".format(max(fitness)))\n",
    "            print(\"This has parameters: {}\".format(cur_model_params[np.argmax(fitness)]))\n",
    "            print()\n",
    "            print(\"Minimum Fitness this iteration: {}\".format(min(fitness)))\n",
    "            print(\"This has parameters: {}\".format(cur_model_params[np.argmin(fitness)]))\n",
    "            print()\n",
    "\n",
    "            cur_model_params = temp_model_params[:]\n",
    "            mut_prob *= mut_decay_rate\n",
    "            mut_prob = max(mut_prob, min_mut_prob)\n",
    "        else:\n",
    "            print(\"We are Done\")\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hyperparameters are: [105.0, 106.0, 0.07148403258762925, 91.0, 82.0, 0.6056116795739639, 73.0, 121.0, 0.4676138859567145, 60.0, 0.261751893640368]\n"
     ]
    }
   ],
   "source": [
    "hyperparams = cur_model_params[0]#np.argmax(fitness) if (type(np.argmax(fitness)) in [np.int64, int]) else np.argmax(fitness)[0]]\n",
    "print(\"The hyperparameters are: {}\".format(hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(hyperparams[0], (3,3), activation = 'relu', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(hyperparams[1], (3,3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(SpatialDropout2D(hyperparams[2]))\n",
    "model.add(Conv2D(hyperparams[3], (3,3), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(hyperparams[4], (3,3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(SpatialDropout2D(hyperparams[5]))\n",
    "model.add(Conv2D(hyperparams[6], (3,3), activation = 'relu', padding='same'))\n",
    "model.add(Conv2D(hyperparams[7], (3,3), activation = 'relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(SpatialDropout2D(hyperparams[8]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hyperparams[9], activation='relu'))\n",
    "model.add(Dropout(hyperparams[10]))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# model.add(Conv2D(128, (3,3), activation = 'relu', padding='same', input_shape=(32, 32, 3)))\n",
    "# model.add(Conv2D(128, (3,3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(SpatialDropout2D(0.2))\n",
    "# model.add(Conv2D(64, (3,3), activation = 'relu', padding='same'))\n",
    "# model.add(Conv2D(64, (3,3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(SpatialDropout2D(0.3))\n",
    "# model.add(Conv2D(128, (3,3), activation = 'relu', padding='same'))\n",
    "# model.add(Conv2D(128, (3,3), activation = 'relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(SpatialDropout2D(0.4))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.8))\n",
    "# model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(epsilon=0.1) , # SGD(learning_rate=0.001, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model\n",
    "\n",
    "[Here](https://medium.com/singlestone/keras-callbacks-monitor-and-improve-your-deep-learning-205a8a27e91c) you can find data on Keras Call Backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7344 - accuracy: 0.7481 - val_loss: 0.6250 - val_accuracy: 0.7871\n",
      "Epoch 2/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7226 - accuracy: 0.7537 - val_loss: 0.6602 - val_accuracy: 0.7745\n",
      "Epoch 3/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7269 - accuracy: 0.7500 - val_loss: 0.6382 - val_accuracy: 0.7867\n",
      "Epoch 4/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7215 - accuracy: 0.7522 - val_loss: 0.6455 - val_accuracy: 0.7807\n",
      "Epoch 5/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7250 - accuracy: 0.7519 - val_loss: 0.6203 - val_accuracy: 0.7917\n",
      "Epoch 6/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7151 - accuracy: 0.7554 - val_loss: 0.5953 - val_accuracy: 0.7961\n",
      "Epoch 7/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7199 - accuracy: 0.7534 - val_loss: 0.6026 - val_accuracy: 0.7965\n",
      "Epoch 8/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7189 - accuracy: 0.7531 - val_loss: 0.6716 - val_accuracy: 0.7751\n",
      "Epoch 9/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7157 - accuracy: 0.7535 - val_loss: 0.5949 - val_accuracy: 0.7994\n",
      "Epoch 10/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7130 - accuracy: 0.7558 - val_loss: 0.6092 - val_accuracy: 0.7950\n",
      "Epoch 11/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7167 - accuracy: 0.7531 - val_loss: 0.5880 - val_accuracy: 0.7974\n",
      "Epoch 12/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7130 - accuracy: 0.7544 - val_loss: 0.6207 - val_accuracy: 0.7897\n",
      "Epoch 13/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7085 - accuracy: 0.7566 - val_loss: 0.5503 - val_accuracy: 0.8109\n",
      "Epoch 14/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7089 - accuracy: 0.7568 - val_loss: 0.5598 - val_accuracy: 0.8064\n",
      "Epoch 15/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7020 - accuracy: 0.7608 - val_loss: 0.5797 - val_accuracy: 0.8043\n",
      "Epoch 16/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7042 - accuracy: 0.7579 - val_loss: 0.5896 - val_accuracy: 0.7985\n",
      "Epoch 17/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7013 - accuracy: 0.7586 - val_loss: 0.6218 - val_accuracy: 0.7907\n",
      "Epoch 18/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7004 - accuracy: 0.7574 - val_loss: 0.5971 - val_accuracy: 0.7964\n",
      "Epoch 19/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7014 - accuracy: 0.7607 - val_loss: 0.5932 - val_accuracy: 0.7987\n",
      "Epoch 20/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6952 - accuracy: 0.7593 - val_loss: 0.5922 - val_accuracy: 0.7995\n",
      "Epoch 21/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6998 - accuracy: 0.7620 - val_loss: 0.5676 - val_accuracy: 0.8071\n",
      "Epoch 22/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.7014 - accuracy: 0.7608 - val_loss: 0.5927 - val_accuracy: 0.8013\n",
      "Epoch 23/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6924 - accuracy: 0.7625 - val_loss: 0.5423 - val_accuracy: 0.8169\n",
      "Epoch 24/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6927 - accuracy: 0.7625 - val_loss: 0.5851 - val_accuracy: 0.7996\n",
      "Epoch 25/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6896 - accuracy: 0.7654 - val_loss: 0.5919 - val_accuracy: 0.8013\n",
      "Epoch 26/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6942 - accuracy: 0.7614 - val_loss: 0.6000 - val_accuracy: 0.7986\n",
      "Epoch 27/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6910 - accuracy: 0.7621 - val_loss: 0.6151 - val_accuracy: 0.7945\n",
      "Epoch 28/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6915 - accuracy: 0.7637 - val_loss: 0.5866 - val_accuracy: 0.8034\n",
      "Epoch 29/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6882 - accuracy: 0.7639 - val_loss: 0.6420 - val_accuracy: 0.7847\n",
      "Epoch 30/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6906 - accuracy: 0.7638 - val_loss: 0.5984 - val_accuracy: 0.8000\n",
      "Epoch 31/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6894 - accuracy: 0.7648 - val_loss: 0.6010 - val_accuracy: 0.7991\n",
      "Epoch 32/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6829 - accuracy: 0.7664 - val_loss: 0.6052 - val_accuracy: 0.7990\n",
      "Epoch 33/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6857 - accuracy: 0.7663 - val_loss: 0.5751 - val_accuracy: 0.8049\n",
      "Epoch 34/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6789 - accuracy: 0.7685 - val_loss: 0.5942 - val_accuracy: 0.8011\n",
      "Epoch 35/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6810 - accuracy: 0.7665 - val_loss: 0.6360 - val_accuracy: 0.7898\n",
      "Epoch 36/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6776 - accuracy: 0.7690 - val_loss: 0.5834 - val_accuracy: 0.8044\n",
      "Epoch 37/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6819 - accuracy: 0.7670 - val_loss: 0.6123 - val_accuracy: 0.7966\n",
      "Epoch 38/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6856 - accuracy: 0.7658 - val_loss: 0.6145 - val_accuracy: 0.7960\n",
      "Epoch 39/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6796 - accuracy: 0.7678 - val_loss: 0.5772 - val_accuracy: 0.7999\n",
      "Epoch 40/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6717 - accuracy: 0.7709 - val_loss: 0.5634 - val_accuracy: 0.8103\n",
      "Epoch 41/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6704 - accuracy: 0.7720 - val_loss: 0.5450 - val_accuracy: 0.8162\n",
      "Epoch 42/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6742 - accuracy: 0.7673 - val_loss: 0.5811 - val_accuracy: 0.8055\n",
      "Epoch 43/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6721 - accuracy: 0.7697 - val_loss: 0.5544 - val_accuracy: 0.8101\n",
      "Epoch 44/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6739 - accuracy: 0.7717 - val_loss: 0.5958 - val_accuracy: 0.8013\n",
      "Epoch 45/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6746 - accuracy: 0.7703 - val_loss: 0.6211 - val_accuracy: 0.7930\n",
      "Epoch 46/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6652 - accuracy: 0.7733 - val_loss: 0.5398 - val_accuracy: 0.8179\n",
      "Epoch 47/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6649 - accuracy: 0.7751 - val_loss: 0.5885 - val_accuracy: 0.8027\n",
      "Epoch 48/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6678 - accuracy: 0.7726 - val_loss: 0.5448 - val_accuracy: 0.8156\n",
      "Epoch 49/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6685 - accuracy: 0.7707 - val_loss: 0.5819 - val_accuracy: 0.8052\n",
      "Epoch 50/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6662 - accuracy: 0.7722 - val_loss: 0.5746 - val_accuracy: 0.8080\n",
      "Epoch 51/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6686 - accuracy: 0.7714 - val_loss: 0.5139 - val_accuracy: 0.8196\n",
      "Epoch 52/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6606 - accuracy: 0.7742 - val_loss: 0.5634 - val_accuracy: 0.8094\n",
      "Epoch 53/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6617 - accuracy: 0.7739 - val_loss: 0.5533 - val_accuracy: 0.8131\n",
      "Epoch 54/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6599 - accuracy: 0.7749 - val_loss: 0.6405 - val_accuracy: 0.7904\n",
      "Epoch 55/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6622 - accuracy: 0.7730 - val_loss: 0.5971 - val_accuracy: 0.8043\n",
      "Epoch 56/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6604 - accuracy: 0.7746 - val_loss: 0.5776 - val_accuracy: 0.8066\n",
      "Epoch 57/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6588 - accuracy: 0.7752 - val_loss: 0.5822 - val_accuracy: 0.8034\n",
      "Epoch 58/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6564 - accuracy: 0.7761 - val_loss: 0.5786 - val_accuracy: 0.8062\n",
      "Epoch 59/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6536 - accuracy: 0.7766 - val_loss: 0.5736 - val_accuracy: 0.8075\n",
      "Epoch 60/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6569 - accuracy: 0.7738 - val_loss: 0.5492 - val_accuracy: 0.8173\n",
      "Epoch 61/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6542 - accuracy: 0.7758 - val_loss: 0.5900 - val_accuracy: 0.8046\n",
      "Epoch 62/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6530 - accuracy: 0.7776 - val_loss: 0.5653 - val_accuracy: 0.8078\n",
      "Epoch 63/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6561 - accuracy: 0.7759 - val_loss: 0.5819 - val_accuracy: 0.8034\n",
      "Epoch 64/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6502 - accuracy: 0.7765 - val_loss: 0.5308 - val_accuracy: 0.8233\n",
      "Epoch 65/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6513 - accuracy: 0.7773 - val_loss: 0.5217 - val_accuracy: 0.8238\n",
      "Epoch 66/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6501 - accuracy: 0.7774 - val_loss: 0.5538 - val_accuracy: 0.8146\n",
      "Epoch 67/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6523 - accuracy: 0.7773 - val_loss: 0.5331 - val_accuracy: 0.8238\n",
      "Epoch 68/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6448 - accuracy: 0.7786 - val_loss: 0.5961 - val_accuracy: 0.8025\n",
      "Epoch 69/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6461 - accuracy: 0.7781 - val_loss: 0.5362 - val_accuracy: 0.8181\n",
      "Epoch 70/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6428 - accuracy: 0.7793 - val_loss: 0.5651 - val_accuracy: 0.8137\n",
      "Epoch 71/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6393 - accuracy: 0.7824 - val_loss: 0.5466 - val_accuracy: 0.8164\n",
      "Epoch 72/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6438 - accuracy: 0.7802 - val_loss: 0.5166 - val_accuracy: 0.8240\n",
      "Epoch 73/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6404 - accuracy: 0.7804 - val_loss: 0.5381 - val_accuracy: 0.8206\n",
      "Epoch 74/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6456 - accuracy: 0.7790 - val_loss: 0.5352 - val_accuracy: 0.8219\n",
      "Epoch 75/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6381 - accuracy: 0.7833 - val_loss: 0.5108 - val_accuracy: 0.8254\n",
      "Epoch 76/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6389 - accuracy: 0.7839 - val_loss: 0.5610 - val_accuracy: 0.8143\n",
      "Epoch 77/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6394 - accuracy: 0.7834 - val_loss: 0.5464 - val_accuracy: 0.8173\n",
      "Epoch 78/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6389 - accuracy: 0.7815 - val_loss: 0.5102 - val_accuracy: 0.8259\n",
      "Epoch 79/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6370 - accuracy: 0.7823 - val_loss: 0.5501 - val_accuracy: 0.8173\n",
      "Epoch 80/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6342 - accuracy: 0.7839 - val_loss: 0.5738 - val_accuracy: 0.8131\n",
      "Epoch 81/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6352 - accuracy: 0.7836 - val_loss: 0.5361 - val_accuracy: 0.8180\n",
      "Epoch 82/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6333 - accuracy: 0.7838 - val_loss: 0.5265 - val_accuracy: 0.8221\n",
      "Epoch 83/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6362 - accuracy: 0.7832 - val_loss: 0.5819 - val_accuracy: 0.8095\n",
      "Epoch 84/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6364 - accuracy: 0.7839 - val_loss: 0.5872 - val_accuracy: 0.8080\n",
      "Epoch 85/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6337 - accuracy: 0.7861 - val_loss: 0.5851 - val_accuracy: 0.8093\n",
      "Epoch 86/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6320 - accuracy: 0.7842 - val_loss: 0.5602 - val_accuracy: 0.8129\n",
      "Epoch 87/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6284 - accuracy: 0.7873 - val_loss: 0.5396 - val_accuracy: 0.8196\n",
      "Epoch 88/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6292 - accuracy: 0.7861 - val_loss: 0.5136 - val_accuracy: 0.8274\n",
      "Epoch 89/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6272 - accuracy: 0.7874 - val_loss: 0.5496 - val_accuracy: 0.8167\n",
      "Epoch 90/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6286 - accuracy: 0.7863 - val_loss: 0.5198 - val_accuracy: 0.8240\n",
      "Epoch 91/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6306 - accuracy: 0.7872 - val_loss: 0.5201 - val_accuracy: 0.8222\n",
      "Epoch 92/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6303 - accuracy: 0.7858 - val_loss: 0.5696 - val_accuracy: 0.8125\n",
      "Epoch 93/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6306 - accuracy: 0.7836 - val_loss: 0.5575 - val_accuracy: 0.8105\n",
      "Epoch 94/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6218 - accuracy: 0.7910 - val_loss: 0.6047 - val_accuracy: 0.8014\n",
      "Epoch 95/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6266 - accuracy: 0.7862 - val_loss: 0.5362 - val_accuracy: 0.8195\n",
      "Epoch 96/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6261 - accuracy: 0.7875 - val_loss: 0.5355 - val_accuracy: 0.8251\n",
      "Epoch 97/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6226 - accuracy: 0.7888 - val_loss: 0.5668 - val_accuracy: 0.8142\n",
      "Epoch 98/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6246 - accuracy: 0.7864 - val_loss: 0.4951 - val_accuracy: 0.8317\n",
      "Epoch 99/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6227 - accuracy: 0.7877 - val_loss: 0.5682 - val_accuracy: 0.8167\n",
      "Epoch 100/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6270 - accuracy: 0.7858 - val_loss: 0.5648 - val_accuracy: 0.8145\n",
      "Epoch 101/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6225 - accuracy: 0.7871 - val_loss: 0.5225 - val_accuracy: 0.8214\n",
      "Epoch 102/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6202 - accuracy: 0.7901 - val_loss: 0.5597 - val_accuracy: 0.8139\n",
      "Epoch 103/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6174 - accuracy: 0.7902 - val_loss: 0.5544 - val_accuracy: 0.8140\n",
      "Epoch 104/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6182 - accuracy: 0.7892 - val_loss: 0.4992 - val_accuracy: 0.8320\n",
      "Epoch 105/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6143 - accuracy: 0.7914 - val_loss: 0.5541 - val_accuracy: 0.8156\n",
      "Epoch 106/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6144 - accuracy: 0.7929 - val_loss: 0.5360 - val_accuracy: 0.8235\n",
      "Epoch 107/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6142 - accuracy: 0.7905 - val_loss: 0.5171 - val_accuracy: 0.8253\n",
      "Epoch 108/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6142 - accuracy: 0.7924 - val_loss: 0.5575 - val_accuracy: 0.8164\n",
      "Epoch 109/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6114 - accuracy: 0.7918 - val_loss: 0.5636 - val_accuracy: 0.8147\n",
      "Epoch 110/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6140 - accuracy: 0.7921 - val_loss: 0.5516 - val_accuracy: 0.8185\n",
      "Epoch 111/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6125 - accuracy: 0.7912 - val_loss: 0.5252 - val_accuracy: 0.8210\n",
      "Epoch 112/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6077 - accuracy: 0.7929 - val_loss: 0.5259 - val_accuracy: 0.8262\n",
      "Epoch 113/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6120 - accuracy: 0.7918 - val_loss: 0.5370 - val_accuracy: 0.8221\n",
      "Epoch 114/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6090 - accuracy: 0.7927 - val_loss: 0.5927 - val_accuracy: 0.8072\n",
      "Epoch 115/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6099 - accuracy: 0.7938 - val_loss: 0.5665 - val_accuracy: 0.8128\n",
      "Epoch 116/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6085 - accuracy: 0.7929 - val_loss: 0.5275 - val_accuracy: 0.8237\n",
      "Epoch 117/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6136 - accuracy: 0.7923 - val_loss: 0.5223 - val_accuracy: 0.8270\n",
      "Epoch 118/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6118 - accuracy: 0.7923 - val_loss: 0.4990 - val_accuracy: 0.8312\n",
      "Epoch 119/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6043 - accuracy: 0.7944 - val_loss: 0.5022 - val_accuracy: 0.8349\n",
      "Epoch 120/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6065 - accuracy: 0.7925 - val_loss: 0.5280 - val_accuracy: 0.8224\n",
      "Epoch 121/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6136 - accuracy: 0.7911 - val_loss: 0.4995 - val_accuracy: 0.8333\n",
      "Epoch 122/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6157 - accuracy: 0.7911 - val_loss: 0.5489 - val_accuracy: 0.8185\n",
      "Epoch 123/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6011 - accuracy: 0.7979 - val_loss: 0.5540 - val_accuracy: 0.8185\n",
      "Epoch 124/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6046 - accuracy: 0.7936 - val_loss: 0.5328 - val_accuracy: 0.8239\n",
      "Epoch 125/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6089 - accuracy: 0.7940 - val_loss: 0.5586 - val_accuracy: 0.8201\n",
      "Epoch 126/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5997 - accuracy: 0.7980 - val_loss: 0.5106 - val_accuracy: 0.8309\n",
      "Epoch 127/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6042 - accuracy: 0.7942 - val_loss: 0.5268 - val_accuracy: 0.8263\n",
      "Epoch 128/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6008 - accuracy: 0.7947 - val_loss: 0.5387 - val_accuracy: 0.8239\n",
      "Epoch 129/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6049 - accuracy: 0.7945 - val_loss: 0.5272 - val_accuracy: 0.8296\n",
      "Epoch 130/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6012 - accuracy: 0.7951 - val_loss: 0.5368 - val_accuracy: 0.8195\n",
      "Epoch 131/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5953 - accuracy: 0.7978 - val_loss: 0.4965 - val_accuracy: 0.8338\n",
      "Epoch 132/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5976 - accuracy: 0.7960 - val_loss: 0.5563 - val_accuracy: 0.8230\n",
      "Epoch 133/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6055 - accuracy: 0.7943 - val_loss: 0.5183 - val_accuracy: 0.8259\n",
      "Epoch 134/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6002 - accuracy: 0.7980 - val_loss: 0.4837 - val_accuracy: 0.8366\n",
      "Epoch 135/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6022 - accuracy: 0.7975 - val_loss: 0.5143 - val_accuracy: 0.8328\n",
      "Epoch 136/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5963 - accuracy: 0.7983 - val_loss: 0.5126 - val_accuracy: 0.8289\n",
      "Epoch 137/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5942 - accuracy: 0.7998 - val_loss: 0.5420 - val_accuracy: 0.8225\n",
      "Epoch 138/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5957 - accuracy: 0.7978 - val_loss: 0.5093 - val_accuracy: 0.8341\n",
      "Epoch 139/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5935 - accuracy: 0.7976 - val_loss: 0.5307 - val_accuracy: 0.8246\n",
      "Epoch 140/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5938 - accuracy: 0.7999 - val_loss: 0.4931 - val_accuracy: 0.8373\n",
      "Epoch 141/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.6025 - accuracy: 0.7964 - val_loss: 0.5213 - val_accuracy: 0.8300\n",
      "Epoch 142/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5913 - accuracy: 0.7980 - val_loss: 0.5577 - val_accuracy: 0.8196\n",
      "Epoch 143/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5937 - accuracy: 0.8002 - val_loss: 0.4954 - val_accuracy: 0.8360\n",
      "Epoch 144/150\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5942 - accuracy: 0.7978 - val_loss: 0.5162 - val_accuracy: 0.8309\n",
      "Epoch 145/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5885 - accuracy: 0.8016 - val_loss: 0.5259 - val_accuracy: 0.8265\n",
      "Epoch 146/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5953 - accuracy: 0.7975 - val_loss: 0.5521 - val_accuracy: 0.8198\n",
      "Epoch 147/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5912 - accuracy: 0.7995 - val_loss: 0.5003 - val_accuracy: 0.8348\n",
      "Epoch 148/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5888 - accuracy: 0.8009 - val_loss: 0.5625 - val_accuracy: 0.8192\n",
      "Epoch 149/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5851 - accuracy: 0.8016 - val_loss: 0.5238 - val_accuracy: 0.8253\n",
      "Epoch 150/150\n",
      "1563/1563 [==============================] - 18s 12ms/step - loss: 0.5937 - accuracy: 0.7978 - val_loss: 0.5305 - val_accuracy: 0.8234\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train, Y_train, batch_size=32),\n",
    "                    callbacks = CSVLogger('Training.log'),\n",
    "                    epochs=150, verbose=1,\n",
    "                    validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "[Here] is some information on simple pandas dataframe manipulation and [here](https://pandas.pydata.org/pandas-docs/version/0.13/visualization.html) is information on plotting said information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5305095314979553\n",
      "Accuracy: 0.8234000205993652\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28f0b708548>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3gc1dWH36veu2TJkmzJvRdcMMWADQbb9NBMCUmAOCRASIFAEkj/EvIRCBDaRwg1EIdA6AZMsak2bhj3IlfJsi1ZspolWe1+f5wZ7UpaNVvrtud9Hj2rnZmduTPS3t895Z5rrLUoiqIogUvQkW6AoiiKcmRRIVAURQlwVAgURVECHBUCRVGUAEeFQFEUJcBRIVAURQlwVAgUxQ8YY6qMMf2O4PUnG2M2HKnrK8cWKgSK3zHGbDPGnHWk23E4sdbGWGu3ABhjnjHG/MGf1zPGWGPMAK/rf2qtHezPayrHDyoEinIIGGNCjodrKIGNCoFyxDDGhBtjHjDGFDo/Dxhjwp19KcaYt4wxZcaYUmPMp8aYIGffHcaYncaYSmPMBmPMme2cP94Y85wxptgYs90Yc5cxJsi5bpkxZoTXsanGmBpjTJrz/jxjzArnuC+MMaO8jt3mtGElsN9XR+2O0I0xs4GrgZ857qI3nf29jTGvOG3baoz5oddnf2OMedkY809jTAXwbWPMRGPMQqc9u4wxDxtjwpzjP3E++rVzjSuMMWcYYwq8zjnUGLPA+fwaY8wFXvueMcY8Yox523mmXxpj+jv7jDHmr8aYImNMuTFmpfdzU44TrLX6oz9+/QG2AWf52P47YBGQBqQCXwC/d/b9CXgcCHV+JgMGGAzkA72d43KA/u1c9zngdSDWOW4jcL2z7yngf7yOvQl41/n9BKAIOBEIBr7l3EO41/2sALKByHaubYEBzu/PAH/w2hcELAN+BYQB/YAtwDnO/t8A9cBFzrGRwDhgEhDi3Ms64Ee+rue8PwMocH4PBfKAXzjXmwpUAoO92lcKTHTO/wIwx9l3jtPWBOf5DwUyjvT/lP707I9aBMqR5Grgd9baImttMfBb4JvOvnogA+hrra234vO2QCMQDgwzxoRaa7dZaze3PrExJhi4Avi5tbbSWrsNuM/r/C8CV3p95CpnG8B3gf+z1n5prW201j4LHEA6YpeHrLX51tqag7jvCUCqtfZ31to6K7GEvwOzvI5ZaK19zVrbZK2tsdYus9YustY2OPfyf8DpXbzeJCAGuMe53kfAW7S8//9aaxdbaxsQIRjjbK9HhHQIYKy166y1uw7inpWjGBUC5UjSG9ju9X67sw3gXmQUO88Ys8UYcyeAtTYP+BEyai4yxswxxvSmLSnI6Lf1+TOd3z8CIo0xJxpj+iId36vOvr7ATx03SpkxpgwZ/XtfJ/9gbtjr/L1bnf8XQK/2zm+MGeS4ynY77qI/OvfYFXoD+dbaJq9t3s8CYLfX79WIcOCIxsPAI8AeY8wTxpi4Ll5XOUZQIVCOJIVIp+jSx9mGM4r/qbW2H3A+8BM3FmCtfdFae6rzWQv82ce59yKj2dbn3+mcowl4CRkVXwW8Za2tdI7LR9xGCV4/Udbaf3mdqztle1sfmw9sbXX+WGvtzA4+8xiwHhhorY1DhMN08fqFQLYbY3FofhadNt7ah6y144DhwCDg9i5eVzlGUCFQDhehxpgIr58Q4F/AXU6gNgXxmf8TmoO1A4wxBqhAXEKNxpjBxpipTlC5Fqhx9rXAWtuIdPT/Y4yJdUb9P3HP7/Ai4j66Go9bCMRNc6NjLRhjTLQx5lxjTOxB3vseJA7gshiocALOkcaYYGPMCGPMhA7OEYs8hypjzBDg+51cw5svgf1IwDrUGHMGIq5zOmu4MWaC8xxCnXPU4uN5K8c2KgTK4WIu0mm7P78B/gAsBVYCq4DlzjaAgcAHQBWwEHjUWrsAiQ/cg4z4dyOB5l+0c81bkM5rC/AZ0tk/5e601rodZG/gHa/tS5E4wcPAPsRF9e2DvXHgH0hMo8wY85ojUucj7qitzr08CcR3cI7bEMulEhGqf7fa/xvgWecal3vvsNbWARcAM5xrPQpca61d34W2xznX24e4k0qAv3Thc8oxhJH4m6IoihKoqEWgKIoS4KgQKIqiBDgqBIqiKAGOCoGiKEqAc8wVs0pJSbE5OTlHuhmKoijHFMuWLdtrrU31te+YE4KcnByWLl16pJuhKIpyTGGM2d7evoByDWmqrKIoSlsCRggWbSnhgoc/p6y67kg3RVEU5agiYIQgPjKUNYXl3Ddv45FuiqIoylHFMRcjOFiGZsRx7Uk5PLdwG1dMyCY+MpRXv9rJrInZpMVGHOnmKYriZ+rr6ykoKKC2tvZIN8WvREREkJWVRWhoaJc/c8yVmBg/frw92GBxeU09U/+ygOjwEIoqa6mtbyI1Npz/uWgEX24t5ZXlBfzx4pHMHJnRw61WFOVIs3XrVmJjY0lOTkZqGR5/WGspKSmhsrKS3NzcFvuMMcusteN9fS5gXEMg7qFfzBzKjtJqTh+UynPXTSQmPITZzy/jmS+2ER4SxJ2vrKSwrIaaukae/nwrzy/azud5e6mt14KLinIsU1tbe1yLAIAxhuTk5G5bPQHjGnK5ZFwWkwemkBYn7qDXbz6Fl5bkc9ZQWRNk5kOfctOLyymvqWdL8f7mz6XEhPGtk3K48sQ+pMSEU1lbz8vLCkiPi+Cc4ekEBR2//1yKcrxwPIuAy8HcY8AJAdAsAgBxEaHcMNlTxv035w/nZ6+sJCM+gn9efyID0mJYU1jO84u2c9/7G3nww02cMiCFrwvKKKuuB2BEZhy/nDmMk/onH/Z7URRFOVQCUgg64rLxWWQkRDAqK4H4SAm2pMdHcObQXuQVVfKfpQW8vWoXY7IT+NFZg9hcVMX972/kyr8v4pITsrh0XBa19Y0M6x1HrzgNQiuKIpSVlfHiiy/ygx/8oFufmzlzJi+++CIJCQl+apmfg8XGmOnAg0Aw8KS19p5W+29HVocCEaWhyKLepe2d81CCxf6itr6Rhz7cxBOfbKGhSZ5nYlQoL9wwiWG9dXlXRTkaWLduHUOHDj1i19+2bRvnnXceq1evbrG9sbGR4ODgHr2Wr3vtKFjsN4vAGBOMLHg9DSgAlhhj3rDWrnWPsdbeiyxSjjHmfODHHYnA0UpEaDA/mz6EWRP6ULCvmkZruePllVz15CKumtiHjzcWA3DFhGzOHZlBUnQYxhiq6xoIMoaI0Jb/BPWNTew/0EBCVNiRuB1FUfzAnXfeyebNmxkzZgyhoaHExMSQkZHBihUrWLt2LRdddBH5+fnU1tZy6623Mnv2bMBTVqeqqooZM2Zw6qmn8sUXX5CZmcnrr79OZGTkIbfNbxaBMeYk4DfW2nOc9z8HsNb+qZ3jXwTmW2v/3tF5j0aLwBf5pdXMemIRheU1jOuTyIGGJlbtLAcgNiKE8JBg9lYdIC4ihP/75nhO6p/Mu6t38/TnW/m6oAxr4aXvncTobP+Zg4oSSHiPkn/75hrWFlb06PmH9Y7j1+cPb3e/t0WwYMECzj33XFavXt2c5llaWkpSUhI1NTVMmDCBjz/+mOTk5BZCMGDAAJYuXcqYMWO4/PLLueCCC7jmmms6vFeXI2IRAJlAvtf7AuBEXwcaY6KA6cDN7eyfDcwG6NOnT8+20k9kJ0Xx0W2ns/9AI0nRMrJfWVDGl1tKyd9XzYH6JvokR/HqVzv51lOLObFfEp9u2ku/1GiunNiHeWv28IMXlvPmLac2f15RlOOHiRMntsj1f+ihh3j11VcByM/PZ9OmTSQnt0xAyc3NZcyYMQCMGzeObdu29Uhb/CkEvnKY2jM/zgc+b88tZK19AngCxCLomeb5n/CQYMJDPG6fUVkJjMpqOcK/5sS+fPf5pSzaUsJtZw/ie6f3JzQ4iIvHZnLpYwu5/tkljMlOINgYLhqbSf/UGP76wUb+9eUOTh+cyndOySE6PITa+iZG9I4jJDigpoYoykHR0cj9cBEdHd38+4IFC/jggw9YuHAhUVFRnHHGGT7nAoSHhzf/HhwcTE1NTY+0xZ9CUABke73PAgrbOXYW8C8/tuWoJT4qlH99dxLlNfUtRv6jshL4n4tH8Os31pC3p4oDjU08+dlW4iNDKa+p54zBqSzYUMxbK3c1fyYrMZJrJvVl4+5KPtpQRHxkKIN6xfKDM/oztk/ikbg9RVEcYmNjqays9LmvvLycxMREoqKiWL9+PYsWLTqsbfOnECwBBhpjcoGdSGd/VeuDjDHxwOlAW0dXgBAcZHy6fy4bn81l40VLy2vqeWlJPl9uLeW6U3M4uX8KFbX1zF9fRGhwEHUNTTy7cBv3vLOeuIgQzhraiwONTSzeWspVf/+Sx785jn4p0by5spDTBqYyIjO+3fY0NlneWllIbEQIU4f08tdtK0pAkZyczCmnnMKIESOIjIykVy/Pd2v69Ok8/vjjjBo1isGDBzNp0qTD2jZ/p4/OBB5A0kefstb+jzHmRgBr7ePOMd8GpltrZ3XlnMdKsPhIYK1le0k1GQkRzS6p4soDfOupxWzYU0mTtVgL0WHBPP2diUzMTaKospbY8FAiw4Kx1vLBuiL+/O568oqqAPjptEHcPHVAQMzIVI5vjnT66OGku8HigCo6F6hU1Nbz+zfXkpEQyZTBqdz2n6/ZWVZDTnI063dXkhgVyrdPzmXVzjI+WFdE/9RofjxtEB+tK+K/X+3kyonZ/PHikSoGyjGNCsGRyRpSjhLiIkK597LRze/nzD6Jn/7naw7UN3L7OYNZtn0ff/1gI5Ghwfxi5hC+c0ouocFBnDsyg4yECB6Zv5nk6HBuO2dw8zlq6hopra4jM0FymOsamthWsp/iygPER4Z26HpSFOXoQoWgK2z6ADJPgKikI92SHiE1NpznrpvYYtuW4ipiIkJarM1gjOG2swdTur+Oh+fn0WQtU4aksW5XBQ99uIm9VXXkpkSTlRjJsu37qK7zVGh98trxnDVM4wuKciygQtAZtRXwwqUw9S447bYj3Rq/0S81xud2Ywy/v3AEpfvreHTBZh5dsBmAiblJ3Hh6Lz7L28vu8louHZfFuL6J9IqL4PdvreWn//maubdObrYYSvfXMX99Ebsraqk60MCpA1KYkJPE0m2lLNpayrUn9SUlJtxnGxRF8S8qBJ1RuQuwzmtgEhIcxOPXjGN3RS3rd1USGRbMiblJGGNaVG51eeSqEzjvb59x3dNLOGVACiX7D/DO6t3UNTQBkiX12ILNhASZ5tpMCzYUMWf2JKLC9F9SUQ43gfmtq62AiC4Wg3MFoKrIf+05BjDGkBEfSUZ853VNclKiuf/y0fz2zbW8tDSf4CDDrAnZXD4+mwFpYnks2FDEl1tLmZCThLVwy7+Wc9MLyzlrWC92lFYzIDWGsX0S+Tq/jI82FNE7PoLTBqUyISepTW0mRVEOjcATgh2L4OmZMHsBZIzq/PjK3fK6v9ifrTruOHt4OmcPT293//QRGUwf4VkStLR6BHe/tpr5G4oJMtDklcyWGhtOeXU9f/90KxGhQZzUL5nTBqVy+qBUclOim7OZKmrrCTKGmPDA+7dWjn4Otgw1wAMPPMDs2bOJioryQ8sCUQi2fgq2EVa/0kUhcC2CPf5tV4DzzUl9OaV/MmEhQWTER7KpqJKvdpQxOD2WsdkJ1NQ38uWWUj7eWMzHG4uZ/6YUsR3cK5bLJ2Szbe9+XlqajzEwfXg604alM6x3HBt2V/LU51sJCTI8OGssqbEah1CODGVlZTz66KMHLQTXXHONCkGPsWuFvK57A876DXSWG+9aBFVqEfgb74D1kPQ4hqR73HdRYSFMGZLGlCFpAOwoqWb+hiJeWV7A799aS2iw4RtjswgNMbyxopDXVniqmWQmRFKy/wAXPfI5P5s+mF3ltdTUNTIgLQYLfLRuD1UHGrjv8jHNixEpSk/jXYZ62rRppKWl8dJLL3HgwAEuvvhifvvb37J//34uv/xyCgoKaGxs5O6772bPnj0UFhYyZcoUUlJSmD9/fo+3LfCEoHAFhERC6RYoWge9hnV8vGsR1FVCXTWE+UeRle7RJzmKb52cw7dOziGvqIq4iJDmJUjvPm8YG3ZXsm5XBYlRYUwdksbaXRXc8OxSbp0jAwFjwJ1LmRQdRmVtPdc9s4Tnr59IZGgwTVaC2spxyjt3wu5VPXvO9JEw4552d99zzz2sXr2aFStWMG/ePF5++WUWL16MtZYLLriATz75hOLiYnr37s3bb78NSA2i+Ph47r//fubPn09KSkrPttkhsIRg/16oKICTb4EvHob1b0FjHbx/N5z/ICS1zYBptggA9hdBWM5ha67SNdwAtEt4SHCbSq+jshJ4/8ens3lvFf1TYggPDWJL8X7qGpsYmRnPvDW7uenF5Ux/4FOq6xqoOtDAlRP7cOPp/ZuXHK2pa+SrHfs4oW8iEaHBvL92D3/7aBN3Th/CyQP88wVVjk/mzZvHvHnzGDt2LABVVVVs2rSJyZMnc9ttt3HHHXdw3nnnMXny5MPSnsASgkLHLTTwHMhfAl/9ExY9CjX7YOVLcMadbT9TsQsik6CmVNxDiTmHtcndoq4aXv4OTPsdpA7u/Pijna2fykS+sOjOj+0C8VGhnOBVhdV7GdEZIzN4YNZYnvtiG7kpSdQ3NvHcwu28sGgHV0zI5qT+yfz53fVsL6kmNTaciTlJvL1qFyFBhhueW8oLN5zYXOG1obGJ/QcaCQ8N0gyno5UORu6HA2stP//5z/ne977XZt+yZcuYO3cuP//5zzn77LP51a9+5ff2BJYQ7PpKXjNGwdDzYN5dEJsByQMh74O2QmCd+QM5p8CWBUd/wHjPGtj4LmSf2HUhaGoEE9R5rORwU10Kz54vonbKDw/LJS8Y3ZsLRvdufv+TaYN5dEEec5bs4PlF28lJjuKeb4zkrZW7eHvVLr59cg7Xn5rL1U9+ybX/WExGQgS7ymqpPNDQfI6I0CBGZSVw+qBUzh2ZQU6Kb1Err65nV0UN9Q2WrMRIEnUxouMO7zLU55xzDnfffTdXX301MTEx7Ny5k9DQUBoaGkhKSuKaa64hJiaGZ555psVn1TXUExSugKT+EBEPo6+UGMEpP4LVL8Mn90rn411GoroUmuohY7QIwf6jfC5B2XZ53bux65958izodwac9Wt/tOjgqdoDWCha2+mh/qJPchT3XDKKW84cyPLt+5g2rBcRocHMmtiH8pr65sDyCzecyG/fXENwkOHk/ikkRoURHR7MgYYm9lYdYMm2Uu59bwP3vreBk/olExcZwvaSatLiIjilfzLrd1fy9spd1DXKhLvQYMO0Yb04f1RvJuYmkawzro8LvMtQz5gxg6uuuoqTTjoJgJiYGP75z3+Sl5fH7bffTlBQEKGhoTz22GMAzJ49mxkzZpCRkaHB4kNm19eQ7dTYiU6Bix6V3/ufCR//WTr7Ed/wHO8GitOdNNOjfVKZKwTFG7p2/IEqKFwO4b7LSxxRqkvktav34kcyEyKbS2W4eGcXZSdF8eS3JnR4jt3ltby8LJ//Lt/JnkrISY5me8l+/vROMbHhIVw5MZsT+yUTEmRYvLWU/361k7mrJD51Qp8Ebj1rEKcNTKG6rhFjaDEDu7ymnk83FbNhdyXhIUGEBAdRW99IcnQYV53YV4PeRxEvvvhii/e33npri/f9+/fnnHPOafO5W265hVtuucVv7QocIdhfAuX5MPG7bfdljhMrYfOHrYTACRTHZ0uc4KgXgh3yuneTuLU6c/fsdTrZfdv82qyDYv9eed27sWv3cpSTHh/BzVMHcvPUgS22F1XWEhMe0qJjP3t4Oj+bPoRVO8tZtKWEF7/cwbeeWkxUWDDVdY2EBBnG9U2kb3IUaworWL+7ksYm3+Xkd1fUcvs5Q6iua2D++mLCQ4JIiwtnZGa8z7LiNXWNvLZiJ5MHppCVqBlygULgCEFzfGBM233BIeIeyfuwZafjWgSx6RCTdgy4hhwhqKuEikKIz+z4+KL18lpeAI31EHwU5dBXO0JQVwUVOyE+68i2x094V3v1JiwkiHF9ExnXN5HvTu7HK8sL2LC7kvT4CMprZGW6D9YVMSwjju+f3p8zBqcytk8iTdZS39hEeEgwd722ikfmbyYyNJhXlu9k6979zecfkRnH9afmsm1vNSvyyxiYFkNuajSPzt/MzrIaosKCuf2cwXxzUl9dBzsACBwhiEiAEZeKv98XA86Cta+3nFvgWgSx6RCd2r5FsPx5ySbK7STV65O/SO7y5c8e1C10yr7tEO0IVvH6zoWgeJ282iYRkeT+h96Gwq9g2bNw7v0QdAgdSHWp5/fiDcetEHSFsJAgrpzYp8W2O6YP8XlsMIZQp+P+zQXDWberkr/M20jv+Aj+8a3xpMaGs7awgkcXbObH//6aICPptws3l1DX2MTAtBgeu/oE5izJ57dvruWhDzcxbVgvvnFCVnOhwWMZa+0xfw+dcTCLjQWOEGSNh0v/0f7+/mfKa94HXkLgpI6GhENML9i5rO3nGhvgnZ9B/6mdC8HqVyT4WbkHYnu4Vn9Tk7i+RlwKX78oLpUBZ3b8maL1kjFkm8Q91BNC8OUTcv0pvxAr6mDZvxeCQqCpoWv3orQhPCSYJ64dx2tf7eSKCX2a4xqjshK4ZFwWX+0oY1CvGBKiwqipaySvqIrB6bGEhQQxfUQ68zcU8caKQuau2s1LSwvolxJNYnQYeypqmZCTxE/PHnRUuI+steypOEB6vG/ryiUiIoKSkhKSk5OPWzGw1lJSUkJERMfPojWBIwSdEZ8JqUMlTuCmK1bulvRSkE7Nl0VQvA7qq1tOPPNFbYVYGwCbP4IxVx56m/esgecugm++KtlOjXWQNQ42vtO1IGvxesieBDu+8MQJavbBmtdgwzuSNnvKrR2eogXWyr2BFOk7FCGoLpHYTG25tFM5KNJiI5h9WluBDw0OYmKuJ0MuMiyYkVmeVeWMMUwd0oupQ3pRU9fI3FW7ePWrnTRZy6iseOaukhTa4b3jCDKGIANBxuCORfunRjNrQh+iw4P57/Kd7K06wMjMeE4dKIUCQTqthibbbMG0ZuOeSt78upBhGXFM6pfcJqW2srae++Zt5P21e9hZVsN9l43mknHtW45ZWVkUFBRQXHx8l4uJiIggK6t7FrQKgTcDzoTFT0DdfpnEVLlL3EIgnVr9ftlXuVveh8dCgbN+cmdzDAqXg/s1yXu/Z4Tgk7+IG2jDXMg9TbYl5EDK4M5TSA9UigVxwrWwc6lHCOZcDds/l9F48fruCcGeNVDVQ9Vaq/dKZldsOhR3Ix1W6XEiw4K5ZFxWi062sKyGh+fnkV9aTZO1NDVBo7UY5L/8ta8K+dfifEBKdcRFhPDS0gJCggy3njmQkwck8+s31rBxTxUXjO7N2cN6UVx1gP0HGhicHseOkv384e11HHDWsAgLCeL/rhnXXGuqsraebz21mJUF5UwdkkZ4aBAPz8/jorGZLbKkCstq6BUXQXCQITQ0lNzc3MP23I4l/CoExpjpwINAMPCktbbNdD5jzBnAA0AosNdae7o/29QhA86EhQ/Dts9h0NnS4ac5bqJoZ3S7e5WMwkdfIWUpdjpCULm74+wWVzAGz5RRc1MjBB3CrNPSrbD2Nfl922eQ0Fd+T+gDqYNg/dyWx9dVQ0iEx2/vdq5pw+Sz+7bJ6Hv7FzK3IiIOPvwd1JRBZAJdYvOHnt8PtUjf/hKx0mJ6wbo3D+1cSo/TOyGSP148st39FbX1vPl1IfUNTZw7qjcpMWEU7Kvhz++u5773N3Lf+9ArLpwLRvdm7qpdvLysoM05ThuUyp8vGUlhWQ2/fmMN339hGc9+ZyLBQYY/zl3HyoJyHr7qBKaPSOedVbv4/gvLeXvVLi4Y3Zvy6nrueXc9/1q8g2+ckMl9l40+KHdQ1YEG6huajvsJfn4TAmNMMPAIMA0oAJYYY96w1q71OiYBeBSYbq3dYYw5BF9CD9DnZClIl/eBiELVHi+LwPHpz7sbGmoksDzzL1DgxA2a6iXAGZ3s+9wFS2UG88hLZQS/czlkd5x73iELH5ZR++AZsHGezCYGSMiG1CGw/DnpTEMjZLLcFw/D2X+ASTfKcW6gOG0oJOWKEOz4ErBy7w11sn/Pasg5tWttyvsQ4jIly+eQLYISCeynDoHlz0rMIFrr+XSb/CXw3+/C7PkQmdj58T1EXEQoV5/Yt8W27KQoHr7qBGaO3MXGPZXcMLkfMeEh3H3eMPKKKsmIjyQyNJh1uyuoqWtkyuA0goJkQaRnvjORyx9fyBVPLAIgPCSIv105lukj5Pt5zvB0BqTF8MhHeewur+Hxj7dQXlPPxJwk/rt8JxNzkhjbJ5H75m2gV1wEs0/rx9Ltpdw3byPxkaH8ZNogpg5JayEW+/bXccnjX1BceYC/XDaac4ans6u8hiBjmutPdUZdQxNrd1UwOst3uu7Rgj8tgolAnrV2C4AxZg5wIeA9VfQq4L/W2h0A1tojm58ZGiGd3uYP4dP7Zd2CFCfvOyZVXgsWy6i7bIf40YvXy6i6aK24knwJgbVQsAQGng39pkiANu/9gxeCil1SJ2nUFTBwmojS2tdFrEIjxTUE8M7tYi1U7RGB2zTPIwRF68RCSMyRnx2LYPtnEBQKmePFdQRiAXVFCOr2w46FMHE2fPn4oQmBteIaikoS6wYk5qFC0H22LoB9W2Fv3qENPHqQmSMzmDnSsyhRfGQo4/p64hUn92/7d06JCef5G07kiY83c0LfRKYMSSMuwpPuHBRkuGlKf37876/549z1TB6Ywp0zhjAkPY5vPbWYX72+hiZriQ4PobqugecXyeTLkZnxVNTWc/2zS5k6JI0HZ40hNiKU2vpGbnhuKQX7auiXEs33nl9Gv5RotuzdT1hIEPdeOooLx3SclWet5Wcvf81rKwp56MqxLcqXHG34UwgygXyv9wXAia2OGQSEGmMWALHAg9ba51qfyBgzG5gN0KdPn9a7e5YBZ8K7d8L8P8CoWTDyctnuuoYwcMUL8PQM+Oj3gIUh54kQVO0GRrQ9Z9l26diyxkvnljkeVr0s565n464AACAASURBVE4Z0L321e2HOVeJmJz6Y5kIBzI5LMuZNZ02VNq55lVJi538U1j5b1j5H49Lqni9iFxQsAjBgQpY/7ZT5C1KfmJ6db1U77bPJVg94Ey5t0MRggOVcq7oFI+oFa+T4LU/2b9XBHvwDP9e53BSsllej4M1tzMTIvnthT6+Xw7nj+pNSVUdY/vI/AuXB2eN4eonv2RY7zjuOncYBxoa+dfifPomRXHx2EwareXZL7bxp3fWc+ljC7lwbG/eWFHIhj2VPHLVCZw5NI37521k7a4KLp+QzUfri7h1zgpW5Jdx2bhs+qVGs3ZXBfv21zGpXzLRzgp5//hsK6+tKCQ2IoTfvbmG0wemEh/V/lydLcVV9EmKanfeRlOTJchPs8T9KQS+Wtw6wTUEGAecCUQCC40xi6y1LaKD1tongCcAxo8f3/0k2e4w8Gx475cw5Fy48BGPTz06FYLDZXvGKBh0jqSDgnQcn/xv+5lDbnwga7y8nvpjMdcfPRFGXCJ1zLMneUZs1aVty12AdOKvfFcW17niBU+6Z+pQ6SgTHJGMz4Tr58l717VVtgOWPiWC1WuEBHZznHRXt6JqSR4MPd9zvfSRsHtl157b9s/Fmuhzkjwrd2bwweCWl4hKkfkDcVmw8T2YcMPBn7MrLPkHLPgT3LndI7DHOiV58no0C0H5Tpl/MvS8QzpNSHAQN0xuW0o+OSacd390WottP5k2qPn3IAw3TO7HkPQ4vv/CMv733Q2MzIzngSvGNFsuP585tPn4607J5Vevr+bpz7fx9OfbWpw3LCSI0VnxNDZZVuSXMWNEOjdNGcCFj3zOXa+vpl9KNJ9sKmbf/joareW2swdz4ZhMHl2Qx/++u4FBvWL49fnDOaVVWfMDDY1c+4/FfOOETK6Y0PODYX8KQQGQ7fU+Cyj0ccxea+1+YL8x5hNgNHDk0kSS+8OtK8TX7R3MDQ6B77zjcRUNu0iEIKm/MwKnAyFYIq6ZtOHyfshM+OFX0umseU1G68FhcPtmCdJ+/iB8/oB0qnGOCd3YAK/dCBvehhn3yjlcck4RIUj08sm6NZWa3zvG2I5FUF8jHUM/Jy7vXVq7r5cbKH0kfPGxxAtCOgmWFa2TZxMaKSN51yJoaoLSzZ7n1hWahSBZgu+jLoPPH5IAtOui64iv/inxk9Gzun5NgPIdgJWZ1ioEh48vH4cvHoKfbuz5+TXd4NSBKXz6sylU1zXSu1VtKW/CQoK455JR/OTsQSxYX0zBvmqG9Y4nNiKED9btYfXOcqLCQrhiQjZ3nTuM6PAQrjslh79/uhVjYFyfREZlJbCtZD+3zlnBi1/u4MutpUwZnEpecZVYLxlxnDc6g8vHZ5McHcYvX13Nl1tLufakHL/cuz+FYAkw0BiTC+wEZiExAW9eBx42xoQAYYjr6K9+bFPXSGhHcbPGeX4fOA3CYqWDDY2UjsOXEJRslpnHA84UMXGJSYPz/io/mz+C5y+GrR/LiDzPyb4p3SxC0FgPr9wgWUJT74YTZ7e8Rt9TYMmT7bfbvafY3iIERWtFmIZd6OxzBMQEtRSQ9JESBC9e3/n6zsXrIGuC595Kt8jva/4r1s8PV7QUqo5whcCNCYy6Aj77q5zrxLb129vwyb0iXqOu6F6NovKdzmsB9Bre9c/1FPv3wtzbZb7KwLNg9FWH1jFWl8q8EOh8nsuRxE1d3vqJiP4RJCEqjIQuzpFLi43g8gnZLba1Hsm73HbOYMZkJzIhJ7F5Jb26hib+5+21PLtwO1eMz+aP3xhJfWMTcxbv4LUVhfzvuxt45KM8Th6Qwvtr9/DDMwdy7qgMn+c/VPxWRMRa2wDcDLwHrANestauMcbcaIy50TlmHfAusBJYjKSYrvZXm3qU0Ei47l2plw8y8ayq1ZetsR5euV5q+My8t/1z5UyG8DgJ5lbuhj2OX750q7yufV1EYNrv4LTb2n5+wFkw/GLP7GhfGAN9JokLZ/UrIjjhsbIvPEbcOemjxCJxSXfKcfiKEzQ1Qn2t/H6gSlxPqY5l5O0a2rNGZi7vWe353JYF8toe7mejnMB72lARpZX/9kxa27PG92fr9kvHUlnoKWFdudsjTB1R4Ris5fkdH+cPdnwJj58qcZraMvjgN/DStYd2zr2bPL8fzRaBWyNrS8+XVz5aCA8J5txRGc0iAGJZ/PbCEXz6syncc8lIgoMMEaHBfPuUXF676RQ++MlpnDE4jffX7mH68HR+dGY3rOpu4td5BNbaucDcVtseb/X+XqCDXvIoJt0rcBXTq+2o65N7xfd5+XMQ10HGQHCoFL3b9IHEClzczmv3KvG/T7rJ9+cj4uCyZzpvb59JMqqGtm6T0+/wzKJ2ScqF0GjfQrDgTyIotyz3zGJ2XWTRKZ7Jd6VOsLJ4g8RXNr4Hc66UiWznPei7HlF1KyEAGd3PuwuenikzoUHcc2f+qmVpDO9ZyJvel5H9nKvEQvj+Z+0/G2sl7RXEIjjcvPlD+Rvf8IFYXwvukZ9DSZt13UJpw49ui6BZCBYcF5Vmu0t2km8TZEBaLI9cfQI/31dNelyE3wLF4EeLIOCIzZAaQi4NdTJLeej5HhdMRwycJqPYhY+IqCTmStofSCeaPKCla+lg6OOITEy6CI83E7/bNlgXFCwdaf6itufa+qkIVdHalnMSQCwCkDhBiSNm7kznQqcK7PLn4N07PCvIe1NdIjET12IBqaFkgmRNien3wGm3y3yPxyeL6809j1vGIzJR9hcskxpRezdKvKI9DlRIpVM4/ELQ1CTPcsTFHhfcwGmAV8mOg6EkT2IlfU6UlOOjkQOVsgxsYq4IsSteSjNZie1nEvUUKgQ9RWwvcQ25HdLmj8Q/O/abXfv8gLPktWiNuHiS+nksguL1PbMGcdpwEaxx3+76rOYRl0jnvfUTz7amRo+VsOXjlnMSwCMEVcVe9+BYDbtXySSxST8QodzhQ2T2l3gCxS5xGfDtuXDTIpj0fZh6F9y0WNJd37hZrC/wtGXM1XLuz+6X7Y0HOnaPuPEB8J8QNDXBE1Ng6dMtt1ftlnRZ7xhPxlh5BnkfHPz1SvLkbxKfDQfKxUI72nCtgRMcN9jm49c9dDSjQtBTxGbIl9kNzq36j1Qu7T+1a5+P6w29nCn7A1wh2CoZPvu2Sed5qASHSLbS6Xd0/TPjvi33Nv+PHpEr2SyuH5AAd9E6SBnkERfXlbFnlRwXEulZLGf3SolFuAsEua4jb6pLJHW0NX1PatlZxmfCta+LdfOVYxUUrRXRHHSOBLrXv+WJXbgWli9ct1Birv+EoPArqTm18b2W293OMCHHsy0oSAYEeR92bMm0ucYKeP0maDggf6fkAR6XX2fuoe1ftCz/fThw7z33dEla2LLg8F5fAVQIeg63BEXlLgmebpgLwy/q3mIvg6eLn7jfFBGCAxXOiNn2jEUAEuTuzjoBoREyIW3HQs+X1J1bkH2iTCTbs9rjFgKPRbDjS3ntP1UWy9mzWjrc9JGSngu+O93qve2X6mhNUDAMvUA6lL2bRJTShkmsJcxZgvPs38traReEoM8kCRo3NojbYs1rvt1XB8PGd+V1T6t8iH3OEqOts74GnCXPYvfXXb/G2tckffaLv4nIJg/wzCXxFoKyHfDIiZ5nUrJZJkk+MBLe/7UIyeGgWQT7QP8psO1TefbKYUWFoKfwHnVtmCulqd1ZyV1l8k/hxs+kE0xyqiRueEdee8IiOFhOuFYmdX38v/J+1wqZXDdxtnTwVXtaCoE7ms93hMCd87DqZXlNH+lZ48EVgupSeHCM3O/+vS0DxZ0xcJq8rvy3CHHaUJn3MPpK+Rv0myK+8o4sgvKdEoPIHCelRap2iwvnP9+STKuuUrK5feFwhaA8v+XIu7kzbJmK2GxNdsc95LriFtwDDbUSSG/+3/RyjW2aJy7HwuWeNoE8u88fEAvrUNhfAs+eDy9e0bGQ7tsOoVFiRWZPksFPVzK8jneamiQ5omh958f2ACoEPUWsl0Ww7Bnxy7qTuLpKaCSkOR1+kjNDcuM7YIJ7ZtGYgyUkXPL3d3whVUt3fS1B5P5TaZ5AnuolBGFRMhrft1WCvm6HttrJWEp3AqJxmR4h2PW1HP/6TSIsvlxD7ZHQR66/5El571aMPfcvcMnfxSWW0KfjDqaiUILoiY4Al+VLnSaAr17oWjvKC+Dh8RLw93X+3Ss95cK901/LtnvqRHkTkypLq26c17XrgwTn04Z74ivJAzyTEr2FIH+xs81JcHDX2rjoMZkTs9sr3fdfV8HH93ac8uvN3jx48kxJKNj4rmcGvi/KtsvfxhjP3I3WFtPBYq18F49EFlhrrIU9azs/zqVip1h1K7r4v3eIqBD0FDGO+f3pfTKCPPXHh7ZUY0JfwMhoMamfdMZHktGzRJC+eh52rZTslqgkT5aLt0UAHvdQYo6MSCPiZeZuXKbH7ROf5XHJuJ10TZlYU92xCECsgtoy320B6eBbu4YaG2TBIICKAonTuEtilm133HJG3C1uEb6OKF4vcyY+f1BiO95scjrzyc48EO+UXLcz9MWQ86TQYVc6M2vlOeaeBif/UKyg1CEyRyU0qqVryBUCd+6Luy+ml1OyxAnul26R2ezz/yCTHveXeM5RvtP3c3nrR1LS/Lp3pYLsvLvEXeqLsh2ee08dLP9j7c0R6QoVhS1jWW/eKqVVussnf5G4WE+x4R147KSuj/DdOS2H8iy6gQpBTxEWBeHx8sUZej6Mv+7Qzhca4fGj91R84FCISZMA7NKnpMN1134ecp7MWI5v5dZwhSCpv4z23OJx6V417OOzpINzO7CQCM8Eva6UkvDGdQ+Fx3uemzdJuW1dQx/fAw9PkFTfikIJPrtCsPE9ybSZcIMI05pXO2+DKzT7iySl1ZuN70mHl3uaFDD0HvWW7fDM7m6NW29qzWudX7+qSILzSf1gyi/h5iXydzNG4gSuRVBV7HkWzRaBU6E2PFb+34rXeYL7ACffIhbSwoc913vmXOlovbFWAtYjL5V4y8y/yHU/vc93m72FICRckg4OpvOrq4a3fgL3D4UVL8o2N/W2xEdCQmesebXt3/BQKHCE11dyBMj/4Ly7PAJQ4Qh/T1lHnaBC0JMkZEuHeMHfemZSjBsnOJLxAW/GXuPJtXdnHU/+KdyytK310ywEjovLLSfdWgjqqyXTqnSLHDvpB3Dx/8lM6e6QPUlKfqQN9f3sE3NllOrtm9+yQEbEmz+S0W1cpsyyjkyUOA/ICm3JA7vmHirdIiPv7EliFbhrOjQ2yLUGniNt8y7m19QoYtieRZDcX0TXnQjosvw5eLHVpEC3k0nuJ38P99mDWGXuXAK3UwqJ8BIHZx1tY+QZ1uyTeSDuZMapv5LzuXn+9TUiJuvebPlMy/MlbuS657Inyjya5c+2zX6qLZdBhfe99xrefSGoq4Ynz4Kl/xCX5Mo5st2dqdxe59sR5fkyr8fbAjoUdjkBf+80ZW+2fiKuIHcRJve4qj2HvshTF1Ah6EkufUoK0/XUAiBHmxAMPFs6eBMMvZwvelCwLOvZGjeFNNnpjNqzCEA6QlcIgoLEDdXdZxgSBjP/Fyb/xPd+91m6I+GGA54v57KnZSTtWhLxWRJoTegj4j72aplU52b3tEfpFhGc026XEd26N2R7SZ4Inlt9Nn2EuF5cS6SpoeM6TMO/IZPi3Jo8ICPWje+07Fhc95q3ALjEZng6/fzF0rnnTPYssVq1x5P55lqgRevEDZg2RJ6vuw4HSAwFJGV61X8813H94K4QgKzKV13SdnTrnTHk0mu4uBBry9t9HG0oXC7zby74m8wx2faZiN7WT2V/yZbuZX7VVniuv2dVx8d2BWvlOYJnpN+aZtFy/j8rvP6uRf53D6kQ9CSpg9tmfhwKzaPpo8A1BJIKe9rtko3TOrDZGm/XEEhqYMpgWQXOJc4Vgnz5Arid9cEy5ipxX/nCDQK7X7Tdq6QTi83wZPO4ZUBcN1dfZ/2Dgc45t3/R8fVLt8g99J8qI1M3a8r9IrudY/ooufbejb47w9a41pHrnrLWI2I7Fra8flAIxPs4V2y6ZznV/MViZST29cQGKr2FwImxFG+Q5+QG9xP7SjwDPO0OjZZ0VRe3vlOa1+Al16ly23qOQPO9e4lgL6dsS3esAlcAc08T68M2Sa2mukq5dv3+7pXY8I7H7O7ENbNjEXzw246PqSj0lE1pzyJwn40r9hU7Pd+hztrQA6gQHM0M/4b4Zr1HV0eaE78HF/nIimmNm6nilp9OHwk3L27p+3ctgvwvZeavr5FsT+HOenaFoGCJvE69u2173FdXCFKHSLDb7XQPVMH8P4kwuCPNpkb5ErtWTfooT2e9Z61YUamtrKI9qz0da3sxApAOOGuCRwgqdnoqtHrPzC7ZLOfxVYokNkOWWK0ukRF09kRJcKgtk+KB3hZBbLrEWrZ+LPEOVwgS+ojLqLYCyrbJthNni5vLDX4XrRUh9S7jHZchz7BLQuBmDnVTCIJCZWDRa4QMPlbOkXTg8d9xno1X6QprZc2Rta97tlWXegLaLYSgE4tg0WMye70joXHdgKHRLUf6LlVFHmvJtVjLnfk2Mb0OS8BYheBoJrGvrDN8qDWGjgSjZsE3X/V0qr6ITpUvsFu+IsmPKbJhUdIZul+0gqXiChp1hSdDybUI3I6pr2O9BAVJKrDb6a78twSan54Bj50iboiKQhnlu2KWMUo6kaZG6RyTB3gyv5L6O2tjf+h0hqbj5wQwaLoIS1WxR2CiklsKgete84V7b38dLm6v7ImelOfyfBEE970xMqJ3M51c4XKfS9kOcZMFh8NJN0uKsBtDKVrnO2ur3xkinO5ENWtlfkREvGSfebczIqF7QdKSzfJdCQ6Rtg+/SLZnjofeJzjPxitOsOa/EvR+7Sb52+3fC4+d7Al8u3Mqeo3ouB3WegYH7uJTvti1EjBiFfuyCLZ8LK99T5XBhFsAMS6z8zb0ECoEin8Ij+m8vEZQkGTquB2bPy0CaJlCWrBEfPbBIeJ6CYn0pACPvQau/HfLuRt9JslyoNWlMpJM6g/nPyhun5X/buufzxgtcYGSzTKi817fIDhERtKrXpIMl9iMztOD+0+R160fy/MyQdLOPavFn22t415r5xkOmi7F+sZfLz8Dpnnu133+rkUAYr00OsFut8qutxCUbRc3aHSKrNC36iUJ2u7d6NuCzT1dLBI3bXXNf0UITr+jZXDfGM8Kel2ldGvLQcQwRwj6TxGBDQ7zZA7V7Yd5d0t2UmMdzPslvPZ9iZ80T64rEBfbgDM9sRyf193iibHsXCavteVtS4js+loGAimDJADdej7GlvkSExt2gYh02Q6xEuKz5P+meL2UtF/xoic208OoEChHlvhs8ekGh/tO++xJeo8VN9Sa16Qjc9d4Pus3srSna3lFJki5D2/6nCSvG+ZKMHL4RVKHqdcIKXfdWghcd8r2z+RavVp1jlPuklnMZdu7tmBPxhgZKW+eLx1LyiBn/QkL+Uskw6eusn0hCIuSQOr0P8J594tQuxaA67pwhQE8cYLEHI+bx21n2faWKa9jrhGX06JHpHP1JQQ5p4h7bMsCcS+9c4fc00QfCw31Gi7utPbKXNRWiGuntsKTeux93xmj4PLnJQMtKNjJdnKE4NP7ZbR9wd/g1B/JZLdN8+R5lm4VoSh35pRkjPYszOQL1xqITISdjkXwyb3w4uUtR/67V8q54jMlMcCdvAfO+hrzRShdMduxELAei6CxDubeJoL1xUO+23KIqBAoRxa380/MObQJeF3hjDvlOq9cL+/dFdXCYztfga33WHFjzf+jlKAYeoFsHzhNMorcshvecz+Cw+Hrf8v7tOEtzxcSBpf8QyZ7dWUZz6BgWVp0iyMEGaPFogkKkRnfrhB1ZwZ6G4sgzbOvdTwDxBUVGuVxDbkB7v5T5VyfPSDvW4seiJhkjpOO7N4BYlld8JBvt2f/qRLg/cc033MA1rwqrp11b8qI3J074c2wC0TQQTrY0s2SCrrwYRh5mVh4p/5Y/i7DvyHVbLFiAZQXyACll1csxxfbF4oIDL8Ydn4lI3037uDGFqpLxdWUMcqTHOEdJ9j+hVgJ/c7wJEu4M9rjMz3W2LJnxNI5pwcnuXmhQqAcWVzf+OEooRERB1f8U1wFQaGdd/7ehEaKGFTslJGwO6Fu4Nkyylv1cksxCw5tuZaDr84xKRd+sFDiQF2h3xS5fuUuuX5YtLxueh/WOqmq3XGvRac4azw4FkGsl0Xgjurd+wRx2yT0lY6xptRjIQQ760PXVTnlUNoRtjPukHUlTv4hXPNKy3N7M3g6XDlHBOeJKZ4V61zcVMvtn3sJYAf3ndxfRvtLnxLXizu7OzQSvveJpH272UpFax0hyJLPhUS2n7Wz4wuxFLMmiDW26j+eALgrBK7IZoz2xGlcIagth1dvlGc64hIRHxPkqW0VlynPMjFH3ICX/KN7RSy7wTEYhVSOK+KdEbS/4wMuvYbBZc+Kv7+zFNjW9Jkkk7GGXeDxa2dNlAybA+Vt018zRonfOSzGd0ondB4k9saNE4CnE809TdZz3r1SRt2tZ3h3RFCwzHKu2g2YlvWd4jLgqv/IojbeJHqVivbO9hl7jRSrS+4vs+J9MeAsz7obnTF4hojF36dKeu/Ya2S7u9QpSIfpuuw6+v9J7i9ZaZ8/KGLqndrqWiSJOZ5Ov2Kn/F2CgiXw7brOvKncIyI07jsSlAb46A8ihFHJnvkH+YsBI24w60yoK98pLqG3fizXuu49zxKxcVkecYvLFMvxlq/8bi2rEChHFrfjOtQ5BN1h0Nny010GnCmuhRGXerYFh0gHvfa1tp2R21mnDe2ZL3JijmflOtdlc/qdUuYjJEJGnCFh3Tunu6BSdGpbN42vZ5TQR0bV0FIIUgbKxLHEHvw79j5BOsYN73iEYNfXEmPIHCcB2m2ftT93wiV5gLzWVUqcxBdBTnrv5o/E9ecKdMZoKZboLqG59ROxvozz9+x7spw/PF5cQP2miKvRtQi2fSp/q8gEOUdIpHT+7trhU++C7AmediTlyIS6iHiJ44D/Xaaoa0g50mSMlhzznMlHuiWd0+8MuC0Peo9puX2g02G2KwQ9OA9k5GUyKc8N4IZGSKwgfUTLNMyu4sYJvDOGOsK7828d5L7yXxKM7imMkQmCmz+SuQ7gqR805Rfyuvb19udOuLhB2KR+ki3VHmnDxFIEj7D0HivWnjtK//R+WPJ3WPx/Et/JGC0ddaaTpjrsQkkUKN0iMYmCJZ7/bWPEAi4vEBEIjW67Drk73yWuG5ZiD+BXITDGTDfGbDDG5Blj7vSx/wxjTLkxZoXz8yt/tkc5ColJg5u+PHpmT3eGrwVzBs+QkWDrdNm04ZKN0lV3SFeY+ku47p2eO5+bORTbVSFwOsjQ6O5XiD0YBs+QNNxtTrmILQuko+03RUbhDTWduxVjnTW6p/yy49G1dxzHtQh6j5XXQicYXLBUssW+96m4dFyffd+TJe405DyPtbb8WbGeck71nDcuU7Ku1r4hsZCwVgvXuxZVvJ8z6FrhN9eQMSYYeASYBhQAS4wxb1hrWxfl/tRae16bEyjKsUJUElzrozpoaIRUAD2a6a5F4FoB7hoC/iZnsojOhnckHrBjEZzkpIX2PUniB50lGhgjS5p2hrfl5nbEaUMl+6vwKxms1FWKRdY60eCkmyWrJybVIwSL/w4YaWfzebM8awz4Kqzoukj9nUrdCn9aBBOBPGvtFmttHTAHuNCP11MUpbu4lkCXXUOORdCVuQ89QWiExGDWvSErnjXVeywstwRITyUauEIQkSB+fpARf/oIiU24s7hbB9BBRvZuhd243rJeeWWhfNa7gKKbORQW49tSbHYNHT9CkAl4T4MrcLa15iRjzNfGmHeMMcN97McYM9sYs9QYs7S42P8lWRUlYHCXseyqEEQmOhOdfH5V/cPQC2TCXG25zOZ2fe4Dp0mg2HXfHCqx6XJ/rTOveo+VNRZ2LBILqqO6UOCUGnfSUVvHvtwOfvAM31lrKYOlnEm/0w/uHg4Sf2YN+bIbW9eCXQ70tdZWGWNmAq8BbZKQrbVPAE8AjB8/vodWElcUxVN6uxsj0Nkfe0bMh4NRl4v/Pm14Sx9/2lC4Y1vPtcUYyXzyLpgHIgRLnpRZ5QOndc0llj5KMoxcq8XFtV68M8+8CYuSWe6HGX8KQQHgLa1ZQKH3AdbaCq/f5xpjHjXGpFhrW80gURTFL2SMhlkvekptd4Xurh53qLiL+fiipwXpokfbbnMtjvrqrq9DPnCaCId3oBhk3sd173V/PXM/40/X0BJgoDEm1xgTBswC3vA+wBiTbozIqzFmotOeHloSSFGUTjEGhpx7bFa4PVykDJb8f5DV57pCvzPgh195yly4GCMTEw9HoL0b+O2vb61tMMbcDLwHBANPWWvXGGNudPY/DlwKfN8Y0wDUALOs7c5SQoqiKH4mOESyhHat7F5ZkmMIvw4DrLVzgbmttj3u9fvDwMOtP6coinJUMekHslaAn2r9HGnUHlQURekMd7Gb4xQtMaEoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY5fhcAYM90Ys8EYk2eMubOD4yYYYxqNMZf6sz2KoihKW/wmBMaYYOARYAYwDLjSGDOsneP+DLznr7YoiqIo7eNPi2AikGet3WKtrQPmABf6OO4W4BWgyI9tURRFUdrBn0KQCeR7vS9wtjVjjMkELgYe7+hExpjZxpilxpilxcXFPd5QRVGUQMafQmB8bLOt3j8A3GGtbezoRNbaLUKVsQAADlNJREFUJ6y1462141NTU3usgYqiKEoXhcAYc6sxJs4I/zDGLDfGnN3JxwqAbK/3WUBhq2PGA3OMMduAS4FHjTEXdbHtiqIoSg/QVYvgOmttBXA2kAp8B7ink88sAQYaY3KNMWHALOAN7wOstbnW2hxrbQ7wMvADa+1r3bkBRVEU5dAI6eJxrptnJvC0tfZrY4wv108z1toGY8zNSDZQMPCUtXaNMeZGZ3+HcQFFURTl8NBVIVhmjJkH5AI/N8bEAk2dfchaOxeY22qbTwGw1n67i21RFEVRepCuCsH1wBhgi7W22hiThLiHFEVRlGOcrsYITgI2WGvLjDHXAHcB5f5rlqIoinK46KoQPAZUG2NGAz8DtgPP+a1ViqIoymGjq0LQYK21yMzgB621DwKx/muWoiiKcrjoaoyg0hjzc+CbwGSnPlCo/5qlKIqiHC66ahFcARxA5hPsRkpF3Ou3VimKoiiHjS4JgdP5vwDEG2POA2qttRojUBRFOQ7oaomJy4HFwGXA5cCXunaAoijK8UFXYwS/BCZYa4sAjDGpwAdIWQhFURTlGKarMYIgVwQcSrrxWUVRFOUopqsWwbvGmPeAfznvr6BV6QhFURTl2KRLQmCtvd0YcwlwClKA7glr7at+bZmiKIpyWOiqRYC19hVkSUlFURTlOKJDITDGVNJ2VTEQq8Baa+P80ipFURTlsNGhEFhrtYyEoijKcY5m/iiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuCoECiKogQ4fhUCY8x0Y8wGY0yeMeZOH/svNMasNMasMMYsNcac6s/2KIqiKG3p8oSy7uIsXvMIMA0oAJYYY96w1q71OuxD4A1rrTXGjAJeAob4q02KoihKW/xpEUwE8qy1W6y1dcAcZKnLZqy1Vc4SmADR+J68piiKovgRfwpBJpDv9b7A2dYCY8zFxpj1wNvAdb5OZIyZ7biOlhYXF/ulsYqiKIGKP4XA+NjWZsRvrX3VWjsEuAj4va8TWWufsNaOt9aOT01N7eFmKoqiBDb+FIICINvrfRZQ2N7B1tpPgP7GmBQ/tklRFEVphT+FYAkw0BiTa4wJA2YBb3gfYIwZYIwxzu8nAGHIojeKoijKYcJvWUPW2gZjzM3Ae0Aw8JS1do0x5kZn/+PAJcC1xph6oAa4wit4rCiKohwGzLHW744fP94uXbr0SDdDURTlmMIYs8xaO97XPp1ZrCiKEuCoECiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuCoECiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuCoECiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuCoECiKogQ4KgSKoigBjgqBoihKgKNCoCiKEuCoECiKogQ4KgSKoigBjgqBoihKgONXITDGTDfGbDDG5Blj7vSx/2pjzErn5wtjzGh/tkdRFEVpi9+EwBgTDDwCzACGAVcaY4a1OmwrcLq1dhTwe+AJf7VHURRF8Y0/LYKJQJ61dou1tg6YA1zofYC19gtr7T7n7SIgy4/tURRFUXzgTyHIBPK93hc429rjeuAdP7ZHURRF8UGIH89tfGyzPg80ZgoiBKe2s382MBugT58+PdU+RVEUBf9aBAVAttf7LKCw9UHGmFHAk8CF1toSXyey1j5hrR1vrR2fmprql8YqiqIEKv4UgiXAQGNMrjEmDJgFvOF9gDGmD/Bf4JvW2o1+bIuiKIrSDn5zDVlrG4wxNwPvAcHAU9baNcaYG539jwO/ApKBR40xAA3W2vH+apOiKIrSFmOtT7f9Ucv48ePt0qVLj3QzFEVRjimMMcvaG2jrzGJFUZQAR4VAURQlwFEhUBRFCXBUCBRFUQIcFQJFUZQAR4VAURQlwFEhUBRFCXBUCBRFUQIcFQJFUZQAR4VAURQlwFEhUBRFCXBUCBRFUQIcFQJFUZQAR4VAURQlwFEhUBRFCXBUCBRFUQIcFQJFUZQAR4VAURQlwFEhUBRFCXBUCBRFUQIcFQJFUZQAx69CYIyZbozZYIzJM8bc6WP/EGPMQmPMAWPMbf5si6IoiuKbEH+d2BgTDDwCTAMKgCXGmDestWu9DisFfghc5K92KIqiKB3jT4tgIpBnrd1ira0D5gAXeh9grS2y1i4B6v3YDkVRFKUD/CkEmUC+1/sCZ1u3McbMNsYsNcYsLS4u7pHGKYqiKII/hcD42GYP5kTW2iesteOtteNTU1MPsVmKoiiKN/4UggIg2+t9FlDox+spiqIoB4E/hWAJMNAYk2uMCQNmAW/48XqKoijKQeC3rCFrbYMx5mbgPSAYeMpau8YYc6Oz/3FjTDqwFIgDmowxPwKGWWsr/NUuRVEUpSV+EwIAa+1cYG6rbY97/b4bcRkpiqIoRwidWawoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoCjQqAoihLgqBAoiqIEOCoEiqIoAY4KgaIoSoDjVyEwxkw3xmwwxuQZY+70sd8YYx5y9q80xpzgz/YoiqIobfGbEBhjgoFHgBnAMOBKY8ywVofNAAY6P7OBx/zVHkVRFMU3/rQIJgJ51tot1to6YA5wYatjLgSes8IiIMEYk+HHNimKoiitCPHjuTOBfK/3BcCJXTgmE9jlfZAxZjZiMQBUGWM2HGSbUoC9B/nZw4W2sWfQNvYM2sZD52hpX9/2dvhTCIyPbfYgjsFa+wTwxCE3yJil1trxh3oef6Jt7Bm0jT2DtvHQOdrbB/51DRUA2V7vs4DCgzhGURRF8SP+FIIlwEBjTK4xJgyYBbzR6pg3gGud7KFJQLm1dlfrEymKoij+w2+uIWttgzHmZuA9IBh4ylq7xhhzo7P/cWAuMBPIA6qB/2/v3kKlKsMwjv+fMsxDpWUWqWRZlCh5KMKyQrLoJNpFkaQi1qWQRlGJHajbzheVQScrqaisRCg0C8MLszRPecySUiyDyk5UHp4uvm/XuN17u0Pb64P1/mCYmW+tGZ49s9e8M9/MeteU/ytPdsjTSx0gMh4ekfHwiIyHrvR8yD5gSj6EEEKNxJ7FIYRQc1EIQgih5mpTCA7W7qIKkvpJ+lDSekmfS5qWx4+XtFDS5nzes+KcR0r6TNL8QvP1kPSGpA35sbygwIy35ud4raRXJB1ddUZJz0naKWltw1irmSTNyNvPRklXVJjxwfxcr5b0lqQepWVsWHa7JEvqVWXGg6lFIWhnu4sq7AFusz0QGAFMzbnuAhbZPhNYlK9XaRqwvuF6afkeB96zfTYwhJS1mIyS+gC3AOfZHkz68cT4AjK+AFzZbKzFTPn/cjwwKN/mybxdVZFxITDY9jnAJmBGgRmR1A+4HPi6YayqjG2qRSGgfe0uOpztHbZX5Mu/kF7A+pCyzc6rzQaurSYhSOoLXAM80zBcUr5jgUuAZwFs/2X7JwrKmHUCukjqBHQl7S9TaUbbHwE/NBtuLdM44FXbf9r+ivRLv/OryGh7ge09+epS0v5HRWXMHgXuYP+dZCvJeDB1KQSttbIohqT+wDDgY+Ckpv0p8nnv6pLxGOmfeV/DWEn5Tge+B57P01fPSOpWUkbb24GHSO8Md5D2l1lQUsYGrWUqdRu6CXg3Xy4mo6SxwHbbq5otKiZjo7oUgna1sqiKpO7Am8B02z9XnaeJpDHATtvLq87Shk7AcOAp28OA36h+qmo/eZ59HHAacArQTdLEalP9Z8VtQ5JmkqZX5zQNtbBah2eU1BWYCdzb0uIWxip/LapLISi2lYWko0hFYI7tuXn4u6YurPl8Z0XxRgJjJW0lTaddKunlgvJBem632f44X3+DVBhKyngZ8JXt723vBuYCFxaWsUlrmYrahiRNBsYAE/zvzlClZBxAKvqr8rbTF1gh6WTKybifuhSC9rS76HCSRJrbXm/7kYZF84DJ+fJk4J2OzgZge4btvrb7kx6zD2xPLCUfgO1vgW8knZWHRgPrKCgjaUpohKSu+TkfTfo+qKSMTVrLNA8YL6mzpNNIxxBZVkE+JF0J3AmMtf17w6IiMtpeY7u37f5529kGDM//q0VkPIDtWpxIrSw2AVuAmVXnyZkuIn0sXA2szKergRNIv9jYnM+PLyDrKGB+vlxUPmAo8Gl+HN8GehaY8X5gA7AWeAnoXHVG4BXSdxa7SS9WN7eViTTdsQXYCFxVYcYvSPPsTdvMrNIyNlu+FehVZcaDnaLFRAgh1FxdpoZCCCG0IgpBCCHUXBSCEEKouSgEIYRQc1EIQgih5qIQhNCBJI1q6uIaQimiEIQQQs1FIQihBZImSlomaaWkp/MxGX6V9LCkFZIWSToxrztU0tKG/vg98/gZkt6XtCrfZkC+++769/gJc/LexiFUJgpBCM1IGgjcAIy0PRTYC0wAugErbA8HFgP35Zu8CNzp1B9/TcP4HOAJ20NIvYV25PFhwHTSsTFOJ/V0CqEynaoOEEKBRgPnAp/kN+tdSM3X9gGv5XVeBuZKOg7oYXtxHp8NvC7pGKCP7bcAbP8BkO9vme1t+fpKoD+w5P//s0JoWRSCEA4kYLbtGfsNSvc0W6+t/ixtTff82XB5L7EdhorF1FAIB1oEXCepN/xzHN9TSdvLdXmdG4EltncBP0q6OI9PAhY7HVdim6Rr8310zn3qQyhOvBMJoRnb6yTdDSyQdASpq+RU0kFvBklaDuwifY8AqV3zrPxC/yUwJY9PAp6W9EC+j+s78M8Iod2i+2gI7STpV9vdq84RwuEWU0MhhFBz8YkghBBqLj4RhBBCzUUhCCGEmotCEEIINReFIIQQai4KQQgh1NzfHpLXqv2P9mwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Loss: \" + str(score[0]))\n",
    "print(\"Accuracy: \" + str(score[1]))\n",
    "print()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Loss over iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.plot(list(range(len(history.history['loss']))), history.history['loss'])\n",
    "plt.plot(list(range(len(history.history['val_loss']))), history.history['val_loss'])\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Accuracy over iterations')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(bottom=0, top=1)\n",
    "plt.plot(list(range(len(history.history['accuracy']))), history.history['accuracy'])\n",
    "plt.plot(list(range(len(history.history['val_accuracy']))), history.history['val_accuracy'])\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
